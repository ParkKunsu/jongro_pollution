{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYAVW1ZKSfaP"
      },
      "source": [
        "# Sunspot numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EE5-DRloSZ78"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "import statsmodels.api as sm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAAnRzv3Skl9"
      },
      "outputs": [],
      "source": [
        "print(sm.datasets.sunspots.NOTE)\n",
        "data = sm.datasets.sunspots.load_pandas().data\n",
        "\n",
        "data.index = pd.Index(sm.tsa.datetools.dates_from_range(\"1700\", \"2008\"))\n",
        "data.index.freq = data.index.inferred_freq\n",
        "del data[\"YEAR\"]\n",
        "\n",
        "tst_size = 20\n",
        "trn, tst = data[:-tst_size], data[-tst_size:]\n",
        "\n",
        "ax = trn.plot(title=\"Sunspots\", label='trn', figsize=(12,5))\n",
        "tst.plot(label='tst', ax=ax)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EQmgYkRYymF"
      },
      "outputs": [],
      "source": [
        "res_dict = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oUPtIXCrkkc"
      },
      "source": [
        "## ARIMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwnBfo9-SsbP"
      },
      "outputs": [],
      "source": [
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "ax1 = fig.add_subplot(211)\n",
        "fig = plot_acf(trn.values.squeeze(), lags=40, ax=ax1)\n",
        "ax2 = fig.add_subplot(212)\n",
        "fig = plot_pacf(trn.values.squeeze(), lags=40, ax=ax2)\n",
        "\n",
        "adf = adfuller(trn)\n",
        "print('ADF Statistic: {}'.format(adf[0]))\n",
        "print('p-value: {}'.format(adf[1]))\n",
        "print('Critical Values:')\n",
        "for key, value in adf[4].items():\n",
        "  print('\\t{}: {}'.format(key, value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_e-OwbWSzxL"
      },
      "outputs": [],
      "source": [
        "trn.diff(1).plot(label=\"Diff(1)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1wTOp4QT3Wj"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(12, 8))\n",
        "ax1 = fig.add_subplot(211)\n",
        "fig = plot_acf(trn.diff(1).dropna().values.squeeze(), lags=40, ax=ax1)\n",
        "ax2 = fig.add_subplot(212)\n",
        "fig = plot_pacf(trn.diff(1).dropna().values.squeeze(), lags=40, ax=ax2)\n",
        "\n",
        "adf = adfuller(trn.diff(1).dropna())\n",
        "print('ADF Statistic: {}'.format(adf[0]))\n",
        "print('p-value: {}'.format(adf[1]))\n",
        "print('Critical Values:')\n",
        "for key, value in adf[4].items():\n",
        "  print('\\t{}: {}'.format(key, value))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2kzrmoAV8fK"
      },
      "source": [
        "최종후보 : ARIMA(9,0,0), ARIMA(8,1,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdLyzy1zW8uW"
      },
      "outputs": [],
      "source": [
        "def mape(y_pred, y_true):\n",
        "  return (np.abs(y_pred - y_true)/y_true).mean() * 100\n",
        "\n",
        "def mae(y_pred, y_true):\n",
        "  return np.abs(y_pred - y_true).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgbvmcWHVxQK"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "trn, tst = data.SUNACTIVITY[:-tst_size], data.SUNACTIVITY[-tst_size:]\n",
        "arma_mod90 = ARIMA(trn, order=(9,0,0)).fit() # AR(9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dracN8YGWYI0"
      },
      "outputs": [],
      "source": [
        "prd = arma_mod90.predict(\"1989\", \"2008\", dynamic=True)\n",
        "\n",
        "plt.title(f\"AR(9), MAPE:{mape(prd, tst):.4f}, MAE:{mae(prd, tst):.4f}\")\n",
        "tst.plot(label=\"Target\")\n",
        "prd.plot(label=f\"Prediction\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "res_dict.update({'AR(9)': {'MAPE':mape(prd,tst), 'MAE':mae(prd,tst)}})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9MlIb_xWjBb"
      },
      "outputs": [],
      "source": [
        "arima_mod810 = ARIMA(trn, order=(8,1,0)).fit() # ARIMA(8,1,0)\n",
        "\n",
        "prd = arima_mod810.predict(\"1989\", \"2008\", dynamic=True)\n",
        "\n",
        "plt.title(f\"ARIMA(8,1,0), MAPE:{mape(prd, tst):.4f}, MAE:{mae(prd, tst):.4f}\")\n",
        "tst.plot(label=\"Target\")\n",
        "prd.plot(label=\"Prediction\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "res_dict.update({'ARIMA(8,1,0)': {'MAPE':mape(prd,tst), 'MAE':mae(prd,tst)}})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bzDXcdwYTIJ"
      },
      "source": [
        "# Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ep1E0O4QW1CD"
      },
      "outputs": [],
      "source": [
        "class TimeSeriesDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, ts:np.array, lookback_size:int, forecast_size:int):\n",
        "    self.lookback_size = lookback_size\n",
        "    self.forecast_size = forecast_size\n",
        "    self.data = ts\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data) - self.lookback_size - self.forecast_size + 1\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    idx = (i+self.lookback_size)\n",
        "    look_back = self.data[i:idx]\n",
        "    forecast = self.data[idx:idx+self.forecast_size]\n",
        "\n",
        "    return look_back, forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqFUaHmKZQzU"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "lookback_size = 9\n",
        "forecast_size = 4\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "trn_scaled = scaler.fit_transform(data[:-tst_size].to_numpy(dtype=np.float32)).flatten()\n",
        "tst_scaled = scaler.transform(data[-tst_size-lookback_size:].to_numpy(dtype=np.float32)).flatten()\n",
        "\n",
        "trn_ds = TimeSeriesDataset(trn_scaled, lookback_size, forecast_size)\n",
        "tst_ds = TimeSeriesDataset(tst_scaled, lookback_size, forecast_size)\n",
        "\n",
        "trn_dl = torch.utils.data.DataLoader(trn_ds, batch_size=32, shuffle=True)\n",
        "tst_dl = torch.utils.data.DataLoader(tst_ds, batch_size=tst_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wCnaIJmZ2CW"
      },
      "outputs": [],
      "source": [
        "x, y = next(iter(trn_dl))\n",
        "\n",
        "x.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8tJ5pNYaeDS"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self, d_in, d_out, d_hidden, activation=F.relu):\n",
        "    super().__init__()\n",
        "    self.lin1 = nn.Linear(d_in, d_hidden)\n",
        "    self.lin2 = nn.Linear(d_hidden, d_out)\n",
        "    self.activation = activation\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.lin1(x)\n",
        "    x = self.activation(x)\n",
        "    x = self.lin2(x)\n",
        "    return F.sigmoid(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-asYoLTtsaF"
      },
      "outputs": [],
      "source": [
        "# def mape(y_pred, y_true):\n",
        "#   return (torch.abs(y_pred - y_true)/y_true).mean() * 100\n",
        "\n",
        "# def mae(y_pred, y_true):\n",
        "#   return torch.abs(y_pred - y_true).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMjaJBHys-VV"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import trange\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "net = Net(9, 4, 512)\n",
        "net.to(device)\n",
        "\n",
        "optim = torch.optim.AdamW(net.parameters(), lr=0.0001)\n",
        "\n",
        "pbar = trange(2000)\n",
        "for i in pbar:\n",
        "  net.train()\n",
        "  trn_loss = .0\n",
        "  for x, y in trn_dl:\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    p = net(x)\n",
        "    optim.zero_grad()\n",
        "    loss = F.mse_loss(p, y)\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    trn_loss += loss.item()*len(y)\n",
        "  trn_loss = trn_loss/len(trn_ds)\n",
        "\n",
        "  net.eval()\n",
        "  with torch.inference_mode():\n",
        "    x, y = next(iter(tst_dl))\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    p = net(x)\n",
        "    tst_loss = F.mse_loss(p,y)\n",
        "    # tst_mape = mape(p,y)\n",
        "    # tst_mae = mae(p,y)\n",
        "  pbar.set_postfix({'loss':trn_loss, 'tst_loss':tst_loss.item()})#, 'tst_mape':tst_mape.item(), 'tst_mae':tst_mae.item()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiTas3ImueoU"
      },
      "outputs": [],
      "source": [
        "net.eval()\n",
        "with torch.inference_mode():\n",
        "  x, y = next(iter(tst_dl))\n",
        "  x, y = x.to(device), y.to(device)\n",
        "  p = net(x)\n",
        "\n",
        "def mape(y_pred, y_true):\n",
        "  return (np.abs(y_pred - y_true)/y_true).mean() * 100\n",
        "\n",
        "def mae(y_pred, y_true):\n",
        "  return np.abs(y_pred - y_true).mean()\n",
        "\n",
        "y = scaler.inverse_transform(y.cpu())\n",
        "p = scaler.inverse_transform(p.cpu())\n",
        "\n",
        "y = np.concatenate([y[:,0], y[-1,1:]])\n",
        "p = np.concatenate([p[:,0], p[-1,1:]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGA3t1Uav_ry"
      },
      "outputs": [],
      "source": [
        "plt.title(f\"Neural Network, MAPE:{mape(p,y):.4f}, MAE:{mae(p,y):.4f}\")\n",
        "plt.plot(range(tst_size), y, label=\"True\")\n",
        "plt.plot(range(tst_size), p, label=\"Prediction\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "res_dict.update({'NN(9,512,4)': {'MAPE':mape(p,y), 'MAE':mae(p,y)}})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7KYfOG9x6WI"
      },
      "source": [
        "### Multi-channel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgPSy66Txs3V"
      },
      "outputs": [],
      "source": [
        "m_data = data.copy()\n",
        "m_data['rolling_mean'] = data.SUNACTIVITY.rolling(11).mean()\n",
        "m_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXkodrp1yFf6"
      },
      "outputs": [],
      "source": [
        "m_data = m_data.dropna()\n",
        "\n",
        "lookback_size = 9\n",
        "forecast_size = 4\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "trn_scaled = scaler.fit_transform(m_data[:-tst_size].to_numpy(dtype=np.float32))\n",
        "tst_scaled = scaler.transform(m_data[-tst_size-lookback_size:].to_numpy(dtype=np.float32))\n",
        "\n",
        "trn_ds = TimeSeriesDataset(trn_scaled, lookback_size, forecast_size)\n",
        "tst_ds = TimeSeriesDataset(tst_scaled, lookback_size, forecast_size)\n",
        "\n",
        "trn_dl = torch.utils.data.DataLoader(trn_ds, batch_size=32, shuffle=True)\n",
        "tst_dl = torch.utils.data.DataLoader(tst_ds, batch_size=tst_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pp_AXpdm2Cq3"
      },
      "outputs": [],
      "source": [
        "m_data.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BLR0g0Oy3gT"
      },
      "outputs": [],
      "source": [
        "x, y = next(iter(trn_dl))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqwMFlxVy7I7"
      },
      "outputs": [],
      "source": [
        "x.shape # Batch, Length, Channel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DA9YHvK6y7mK"
      },
      "outputs": [],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ezn9timWzrd_"
      },
      "outputs": [],
      "source": [
        "class NetMulti(nn.Module):\n",
        "  def __init__(self, d_in, d_out, d_hidden, c_in, activation=F.relu):\n",
        "    super().__init__()\n",
        "    self.lin1 = nn.Linear(d_in*c_in, d_hidden)\n",
        "    self.lin2 = nn.Linear(d_hidden, d_out)\n",
        "    self.activation = activation\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.flatten(1)    # (B, d_in * c_in)\n",
        "    x = self.lin1(x)    # (B, d_hidden)\n",
        "    x = self.activation(x)\n",
        "    x = self.lin2(x)    # (B, d_out)\n",
        "    return F.sigmoid(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eql3iJE_1Xpb"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import trange\n",
        "\n",
        "net = NetMulti(9, 4, 512, 2)\n",
        "net.to(device)\n",
        "\n",
        "optim = torch.optim.AdamW(net.parameters(), lr=0.0001)\n",
        "\n",
        "pbar = trange(2000)\n",
        "for i in pbar:\n",
        "  net.train()\n",
        "  trn_loss = .0\n",
        "  for x, y in trn_dl:\n",
        "    x, y = x.flatten(1).to(device), y[:,:,0].to(device)   # (32, 18), (32, 4)\n",
        "    p = net(x)\n",
        "    optim.zero_grad()\n",
        "    loss = F.mse_loss(p, y)\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    trn_loss += loss.item()*len(y)\n",
        "  trn_loss = trn_loss/len(trn_ds)\n",
        "\n",
        "  net.eval()\n",
        "  with torch.inference_mode():\n",
        "    x, y = next(iter(tst_dl))\n",
        "    x, y = x.flatten(1).to(device), y[:,:,0].to(device)\n",
        "    p = net(x)\n",
        "    tst_loss = F.mse_loss(p,y)\n",
        "  pbar.set_postfix({'loss':trn_loss, 'tst_loss':tst_loss.item()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbFE7dnc50Rm"
      },
      "outputs": [],
      "source": [
        "net.eval()\n",
        "with torch.inference_mode():\n",
        "  x, y = next(iter(tst_dl))\n",
        "  x, y = x.flatten(1).to(device), y[:,:,0].to(device)\n",
        "  p = net(x)\n",
        "\n",
        "y = y.cpu()/scaler.scale_[0] + scaler.min_[0]\n",
        "p = p.cpu()/scaler.scale_[0] + scaler.min_[0]\n",
        "\n",
        "y = np.concatenate([y[:,0], y[-1,1:]])\n",
        "p = np.concatenate([p[:,0], p[-1,1:]])\n",
        "\n",
        "plt.title(f\"Neural Network, MAPE:{mape(p,y):.4f}, MAE:{mae(p,y):.4f}\")\n",
        "plt.plot(range(tst_size), y, label=\"True\")\n",
        "plt.plot(range(tst_size), p, label=\"Prediction\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "res_dict.update({'NN(9*2, 512, 4)': {'MAPE':mape(p,y), 'MAE':mae(p,y)}})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO6mJryz8eYs"
      },
      "source": [
        "## Transformer (PatchTST)\n",
        "\n",
        "- `patch length = 16`\n",
        "- `stride = 8`\n",
        "- `n_patches = 6`\n",
        "- `window_size = 48 = 16*6/2`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fa-F6_Df8LnW"
      },
      "outputs": [],
      "source": [
        "class PatchTSDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, ts:np.array, patch_length:int=16, n_patches:int=6, prediction_length:int=4):\n",
        "    self.P = patch_length\n",
        "    self.N = n_patches\n",
        "    self.L = int(patch_length * n_patches / 2)  # look-back window length\n",
        "    self.T = prediction_length\n",
        "    self.data = ts\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data) - self.L - self.T + 1\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    look_back = self.data[i:(i+self.L)]\n",
        "    look_back = np.concatenate([look_back, look_back[-1]*np.ones(int(self.P / 2), dtype=np.float32)])\n",
        "    x = np.array([look_back[i*int(self.P/2):(i+2)*int(self.P/2)] for i in range(self.N)])\n",
        "    y = self.data[(i+self.L):(i+self.L+self.T)]\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVAvrnSU8on-"
      },
      "outputs": [],
      "source": [
        "patch_length = 16\n",
        "n_patches = 8\n",
        "prediction_length = 4\n",
        "window_size = int(patch_length * n_patches / 2)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "trn_scaled = scaler.fit_transform(data[:-tst_size].to_numpy(dtype=np.float32)).flatten()\n",
        "tst_scaled = scaler.transform(data[-tst_size-window_size:].to_numpy(dtype=np.float32)).flatten()\n",
        "\n",
        "trn_ds = PatchTSDataset(trn_scaled, patch_length, n_patches)\n",
        "tst_ds = PatchTSDataset(tst_scaled, patch_length, n_patches)\n",
        "\n",
        "trn_dl = torch.utils.data.DataLoader(trn_ds, batch_size=32, shuffle=True)\n",
        "tst_dl = torch.utils.data.DataLoader(tst_ds, batch_size=tst_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aA26OvwID-8G"
      },
      "outputs": [],
      "source": [
        "scaler2 = MinMaxScaler()\n",
        "\n",
        "trn2_scaled = scaler2.fit_transform(m_data['rolling_mean'][:-tst_size].to_numpy(dtype=np.float32).reshape(-1,1)).flatten()\n",
        "\n",
        "trn2_ds = PatchTSDataset(trn2_scaled, patch_length, n_patches)\n",
        "\n",
        "trn_ds = torch.utils.data.ConcatDataset([trn_ds, trn2_ds])\n",
        "\n",
        "trn_dl = torch.utils.data.DataLoader(trn_ds, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NI4IZGKJ_X7P"
      },
      "outputs": [],
      "source": [
        "x, y = next(iter(trn_dl))\n",
        "x.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpw7osa99lLa"
      },
      "outputs": [],
      "source": [
        "class PatchTST(nn.Module):\n",
        "  def __init__(self, n_token, input_dim, model_dim, num_heads, num_layers, output_dim):\n",
        "    super(PatchTST, self).__init__()\n",
        "    self.patch_embedding = nn.Linear(input_dim, model_dim)    # Input Embedding\n",
        "    self._pos = torch.nn.Parameter(torch.randn(1,1,model_dim))  # Positional Embedding\n",
        "\n",
        "    encoder_layers = nn.TransformerEncoderLayer(d_model=model_dim, nhead=num_heads, batch_first=True)\n",
        "    self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
        "\n",
        "    self.output_layer = nn.Linear(model_dim * n_token, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x shape: (batch_size, n_token, token_size)\n",
        "    x = self.patch_embedding(x)   # (batch_size, n_token, model_dim)\n",
        "    x = x + self._pos\n",
        "    x = self.transformer_encoder(x)   # (batch_size, n_token, model_dim)\n",
        "    x = x.view(x.size(0), -1)       # (batch_size, n_token * model_dim)\n",
        "    output = self.output_layer(x)   # (batch_size, out_dim =4 patch_size == 4)\n",
        "    return F.sigmoid(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "e15ba683e50a4ae1a9131ba235e6a4c6"
          ]
        },
        "id": "47ERmPdh879L",
        "outputId": "bca76be3-e5a8-48d2-8418-acdcedafd38d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e15ba683e50a4ae1a9131ba235e6a4c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = PatchTST(n_patches, patch_length, 512, 8, 4, prediction_length)\n",
        "model.to(device)\n",
        "\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
        "\n",
        "pbar = trange(1000)\n",
        "for _ in pbar:\n",
        "  model.train()\n",
        "  trn_loss = 0.\n",
        "  for x,y in trn_dl:\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    p = model(x)\n",
        "    optim.zero_grad()\n",
        "    loss = F.mse_loss(p, y)\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    trn_loss += loss.item()*len(x)\n",
        "  trn_loss = trn_loss / len(trn_ds)\n",
        "\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    x, y = next(iter(tst_dl))\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    p = model(x)\n",
        "    tst_loss = F.mse_loss(p,y)\n",
        "  pbar.set_postfix({'loss':trn_loss, 'tst_loss':tst_loss.item()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZ-B7Tu-9qQE"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.inference_mode():\n",
        "  x, y = next(iter(tst_dl))\n",
        "  x, y = x.to(device), y.to(device)\n",
        "  p = model(x)\n",
        "\n",
        "y = scaler.inverse_transform(y.cpu())\n",
        "p = scaler.inverse_transform(p.cpu())\n",
        "\n",
        "y = np.concatenate([y[:,0], y[-1,1:]])\n",
        "p = np.concatenate([p[:,0], p[-1,1:]])\n",
        "\n",
        "plt.title(f\"PatchTST (extended dataset), MAPE:{mape(p,y):.4f}, MAE:{mae(p,y):.4f}\")\n",
        "plt.plot(range(tst_size), y, label=\"True\")\n",
        "plt.plot(range(tst_size), p, label=\"Prediction\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "res_dict.update({'PatchTST/8': {'MAPE':mape(p,y), 'MAE':mae(p,y)}})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3Z3CZt4a2GT"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(res_dict)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
